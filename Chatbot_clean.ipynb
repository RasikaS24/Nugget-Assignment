{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vd6Ixy-kTtCX",
    "outputId": "b884ef4e-e480-4e89-cd71-0cdffe81c521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to 'normalized_restaurant_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List all your normalized CSV files here\n",
    "normalized_files = [\n",
    "    \"just_blr_normalized.csv\",\n",
    "    \"mainland_china_normalized.csv\",\n",
    "    \"paakashala_normalized.csv\",\n",
    "    \"punjab_grill_normalized.csv\",\n",
    "    \"rameshwaram_cafe_normalized.csv\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold all DataFrames\n",
    "combined_dataframes = []\n",
    "\n",
    "# Load each file and add to list\n",
    "for file in normalized_files:\n",
    "    if os.path.exists(file):\n",
    "        df = pd.read_csv(file)\n",
    "        combined_dataframes.append(df)\n",
    "    else:\n",
    "        print(f\"File not found: {file}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat(combined_dataframes, ignore_index=True)\n",
    "\n",
    "# Save combined data to a new CSV file\n",
    "combined_df.to_csv(\"normalized_restaurant_data.csv\", index=False)\n",
    "print(\"Combined data saved to 'normalized_restaurant_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GI0lFYfkpLYs",
    "outputId": "64954c58-dd13-450b-bef3-1b7c8bb3976f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset enhanced and saved as 'enhanced_restaurant_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading normalized restaurant dataset\n",
    "df = pd.read_csv(\"normalized_restaurant_data.csv\")\n",
    "\n",
    "\n",
    "# Clean Section and Item Names\n",
    "df[\"section\"] = df[\"section\"].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip().str.title()\n",
    "df[\"item\"] = df[\"item\"].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip().str.title()\n",
    "\n",
    "\n",
    "# Feature Tagging: vegetarian, non-veg, spicy\n",
    "def tag_features(row):\n",
    "    item = row['item'].lower()\n",
    "    desc = str(row['description']).lower()\n",
    "    tags = set()\n",
    "    if any(k in item or k in desc for k in [\"veg\", \"vegetarian\", \"paneer\", \"dal\", \"chole\", \"palak\"]):\n",
    "        tags.add(\"vegetarian\")\n",
    "    if any(k in item or k in desc for k in [\"chicken\", \"fish\", \"egg\", \"mutton\", \"lamb\", \"prawn\"]):\n",
    "        tags.add(\"non-vegetarian\")\n",
    "    if any(k in item or k in desc for k in [\"spicy\", \"chilli\", \"hot\", \"pepper\"]):\n",
    "        tags.add(\"spicy\")\n",
    "    return list(tags)\n",
    "\n",
    "df[\"features\"] = df.apply(tag_features, axis=1)\n",
    "\n",
    "\n",
    "# 3. Fill Missing Descriptions\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\").replace(\"nan\", \"\")\n",
    "df[\"description\"] = df.apply(\n",
    "    lambda row: f\"{row['item']} is a dish from {row['restaurant']} listed under {row['section']}.\"\n",
    "    if row[\"description\"].strip() == \"\" else row[\"description\"], axis=1)\n",
    "\n",
    "\n",
    "# Fill Missing Hours\n",
    "df[\"hours\"] = df[\"hours\"].fillna(\"Hours not available\")\n",
    "\n",
    "\n",
    "# Generate Combined Field for Embedding\n",
    "df[\"combined_text\"] = df.apply(\n",
    "    lambda row: f\"\"\"Restaurant: {row['restaurant']}\n",
    "Section: {row['section']}\n",
    "Item: {row['item']}\n",
    "Price: {row['price']}\n",
    "Description: {row['description']}\n",
    "Features: {', '.join(row['features'])}\n",
    "Location: {row['location']}\n",
    "Contact: {row['contact']}\n",
    "Hours: {row['hours']}\"\"\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Save Enhanced Data\n",
    "df.to_csv(\"enhanced_restaurant_data.csv\", index=False)\n",
    "print(\"Dataset enhanced and saved as 'enhanced_restaurant_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UA1GusFfXf3j"
   },
   "outputs": [],
   "source": [
    "# Install required packages (Colab or local)\n",
    "!pip install -q gradio sentence-transformers transformers scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736,
     "referenced_widgets": [
      "5d1782f493564132b3bdec7f876b5a5c",
      "2410e88ea0df4c8bb81e15d494e1f797",
      "1716c49c6e3f4a6c81f4a198650b5a35",
      "dd95b30563bf4ad88eebb79068e1b476",
      "9c1aa2a9bec94fbbb87ab3c45c100ff7",
      "ff3cb0b0bed24099a628d3a2a8fa97c3",
      "d390b98f6af9479a911b7a3c070b36dc",
      "4e933555bf664d3b8de6657ad75d9e5a",
      "043bbb81326f479fb43d633e38f2e89f",
      "df4c4e1b71734287bbd158c69343a1af",
      "e3ac77bdc41540bc9fe0c703a458953d"
     ]
    },
    "id": "tJOrmiZXqlIX",
    "outputId": "b55c90ed-215e-4cec-9a9d-4804f2d44824"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1782f493564132b3bdec7f876b5a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-771edb1e416c>:68: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://24c01d925db25a23a0.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://24c01d925db25a23a0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Imports\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load enhanced data\n",
    "df = pd.read_csv(\"enhanced_restaurant_data.csv\")\n",
    "text_data = df[\"combined_text\"].tolist()\n",
    "\n",
    "# Load models\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = embedding_model.encode(text_data, show_progress_bar=True)\n",
    "\n",
    "# Chatbot logic\n",
    "def respond(user_query, history):\n",
    "    if not user_query.strip():\n",
    "        warning = \"Please enter a valid question.\"\n",
    "        history.append((user_query, warning))\n",
    "        return history, history, \"\"\n",
    "\n",
    "    query_embedding = embedding_model.encode([user_query])\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "    top_k = 4\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    context = \"\\n\\n\".join([f\"Info {i+1}:\\n{text_data[i]}\" for i in top_indices])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant trained on the menus of five restaurants: Just BLR, Paakashala, Punjab Grill, Mainland China, and The Rameshwaram Café.\n",
    "\n",
    "Use the following restaurant menu information to answer customer questions clearly and factually.\n",
    "\n",
    "Menu Info:\n",
    "{context}\n",
    "\n",
    "Question: {user_query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = generator(prompt, max_length=300, temperature=0.7, do_sample=False)\n",
    "        reply = response[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        reply = f\"⚠️ Sorry, something went wrong: {str(e)}\"\n",
    "\n",
    "    history.append((user_query, reply))\n",
    "    return history, history, \"\"  # Clear input\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🍴 Welcome to the Multi-Restaurant RAG Chatbot!\")\n",
    "    gr.Markdown(\"\"\"\n",
    "🤖 I'm trained on menus from 5 restaurants: **Just BLR**, **Paakashala**, **Punjab Grill**, **Mainland China**, and **The Rameshwaram Café**.\n",
    "💡 I can help you explore dishes, compare prices, check timings, and more.\n",
    "\n",
    "**Try asking:**\n",
    "- *Which places serve vegetarian starters under ₹300?*\n",
    "- *What spicy dishes are served at Punjab Grill?*\n",
    "- *When is Just BLR open?*\n",
    "\"\"\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(label=\"Ask a menu question\", placeholder=\"e.g., Show me veg thali options.\")\n",
    "    state = gr.State([])\n",
    "\n",
    "    msg.submit(respond, [msg, state], [chatbot, state, msg])\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
