{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import csv\n",
        "\n",
        "def is_dish_name(text):\n",
        "    \"\"\"Heuristic: All uppercase or mostly uppercase words.\"\"\"\n",
        "    words = text.strip().split()\n",
        "    if not words:\n",
        "        return False\n",
        "    upper_ratio = sum(1 for w in words if w.isupper()) / len(words)\n",
        "    return upper_ratio > 0.6 or text.isupper()\n",
        "\n",
        "def scrape_and_clean_paakashala(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    raw_text = soup.get_text(separator=\"\\n\")\n",
        "    lines = [line.strip() for line in raw_text.splitlines() if line.strip()]\n",
        "\n",
        "    cleaned_menu = []\n",
        "    current_item = None\n",
        "\n",
        "    for line in lines:\n",
        "        if is_dish_name(line):\n",
        "            # Save previous item if exists\n",
        "            if current_item:\n",
        "                cleaned_menu.append(current_item)\n",
        "            # Start new item\n",
        "            current_item = {\"Item\": line.strip(), \"Description\": \"\"}\n",
        "        else:\n",
        "            # Append to current description if exists\n",
        "            if current_item:\n",
        "                if current_item[\"Description\"]:\n",
        "                    current_item[\"Description\"] += \" \" + line.strip()\n",
        "                else:\n",
        "                    current_item[\"Description\"] = line.strip()\n",
        "\n",
        "    # Add the last item\n",
        "    if current_item:\n",
        "        cleaned_menu.append(current_item)\n",
        "\n",
        "    return cleaned_menu\n",
        "\n",
        "# Run the scraper\n",
        "url = \"https://paakashala.com/paakashala-menu/\"\n",
        "menu_data = scrape_and_clean_paakashala(url)\n",
        "\n",
        "# Save to CSV\n",
        "csv_path = \"paakashala_menu_cleaned.csv\"\n",
        "with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"Item\", \"Description\"])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(menu_data)\n",
        "\n",
        "print(f\"Scraped {len(menu_data)} menu items and saved to '{csv_path}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlowcrHraiT3",
        "outputId": "7d39145c-f4ba-4402-be52-f18da46fee2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 201 menu items and saved to 'paakashala_menu_cleaned.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(\"paakashala_menu_cleaned.csv\")\n",
        "\n",
        "# Remove rows with empty or very short items\n",
        "df = df[df[\"Item\"].str.strip().str.len() > 2]\n",
        "\n",
        "# Drop duplicates based on Item name\n",
        "df = df.drop_duplicates(subset=\"Item\", keep=\"first\")\n",
        "\n",
        "# Remove non-food entries by filtering out addresses or overly long descriptions\n",
        "df = df[df[\"Description\"].str.len() < 300]  # adjust if needed\n",
        "df = df[~df[\"Item\"].str.contains(\"ROAD|BENGALURU|KARNATAKA|INDIA\", case=False)]\n",
        "\n",
        "# Optional: reset index and sort\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Save cleaned file\n",
        "df.to_csv(\"paakashala_menu_final.csv\", index=False)\n",
        "\n",
        "print(f\"Cleaned menu saved to 'paakashala_menu_final.csv' with {len(df)} unique items.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP37FcZkbI-6",
        "outputId": "299c7398-2b64-4100-e189-50eb16db6fcf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned menu saved to 'paakashala_menu_final.csv' with 85 unique items.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def extract_paakashala_info():\n",
        "    url = \"https://paakashala.com/restaurants-kanakapura-road/\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Initialize data dictionary\n",
        "    data = {\n",
        "        \"Name\": \"Paakashala – Kanakapura Road\",\n",
        "        \"Address\": \"\",\n",
        "        \"Phone\": \"\",\n",
        "        \"Email\": \"\",\n",
        "        \"Hours\": \"\"\n",
        "    }\n",
        "\n",
        "    # Extract address\n",
        "    address_tag = soup.find(string=lambda text: \"Kanakapura Rd\" in text)\n",
        "    if address_tag:\n",
        "        data[\"Address\"] = address_tag.strip()\n",
        "\n",
        "    # Extract phone number\n",
        "    phone_tag = soup.find(string=lambda text: \"Phone\" in text)\n",
        "    if phone_tag:\n",
        "        data[\"Phone\"] = phone_tag.split(\":\")[-1].strip()\n",
        "\n",
        "    # Extract email\n",
        "    email_tag = soup.find(string=lambda text: \"Email\" in text)\n",
        "    if email_tag:\n",
        "        data[\"Email\"] = email_tag.split(\":\")[-1].strip()\n",
        "\n",
        "    # Extract operating hours\n",
        "    timings_tag = soup.find(string=lambda text: \"Timings\" in text)\n",
        "    if timings_tag:\n",
        "        data[\"Hours\"] = timings_tag.split(\":\")[-1].strip()\n",
        "\n",
        "    return data\n",
        "\n",
        "def save_to_csv(data, filename=\"paakashala_kanakapura_info.csv\"):\n",
        "    with open(filename, mode=\"w\", newline='', encoding=\"utf-8\") as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Field\", \"Information\"])\n",
        "        for key, value in data.items():\n",
        "            writer.writerow([key, value])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    info = extract_paakashala_info()\n",
        "    save_to_csv(info)\n",
        "    print(\"Paakashala – Kanakapura Road information saved to 'paakashala_kanakapura_info.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lJuqir63Sk6",
        "outputId": "e0bad371-2367-4b2a-90c6-9e6cff7e545d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paakashala – Kanakapura Road information saved to 'paakashala_kanakapura_info.csv'\n"
          ]
        }
      ]
    }
  ]
}